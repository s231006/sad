<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Food Detector (Llama 3.2 Vision)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f0f4f8;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        .container {
            background-color: #ffffff;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
            width: 100%;
            max-width: 600px;
            text-align: center;
        }
        .file-input-wrapper {
            position: relative;
            overflow: hidden;
            display: inline-block;
            cursor: pointer;
            width: 100%;
        }
        .file-input-wrapper input[type=file] {
            position: absolute;
            left: 0;
            top: 0;
            opacity: 0;
            cursor: pointer;
            width: 100%;
            height: 100%;
        }
        .upload-button {
            background-color: #4f46e5;
            color: white;
            padding: 12px 20px;
            border-radius: 10px;
            font-weight: 600;
            transition: background-color 0.3s ease;
            display: inline-block;
            margin-top: 15px;
            cursor: pointer;
        }
        .upload-button:hover {
            background-color: #4338ca;
        }
        #image-preview {
            max-width: 100%;
            max-height: 300px;
            margin-top: 20px;
            border-radius: 10px;
            object-fit: contain;
            display: none; /* Hidden by default */
        }
        .action-button {
            background-color: #10b981;
            color: white;
            padding: 12px 25px;
            border-radius: 10px;
            font-weight: 600;
            transition: background-color 0.3s ease;
            border: none;
            cursor: pointer;
            margin-top: 20px;
        }
        .action-button:hover {
            background-color: #059669;
        }
        .action-button:disabled {
            background-color: #a7f3d0;
            cursor: not-allowed;
        }
        #loading-indicator {
            display: none;
            margin-top: 20px;
            font-weight: 500;
            color: #4b5563;
        }
        #results-area {
            margin-top: 30px;
            padding: 20px;
            background-color: #e2e8f0;
            border-radius: 10px;
            text-align: left;
            min-height: 80px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.1em;
            color: #334155;
            word-wrap: break-word; /* Ensure text wraps */
        }
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        .fade-in {
            animation: fadeIn 0.5s ease-in-out;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="text-3xl font-bold text-gray-800 mb-6">Food Detector</h1>
        <p class="text-sm text-gray-600 mb-4">
            (Using OpenRouter: Llama 3.2 Vision - This model can analyze images!)
        </p>

        <div class="mb-6">
            <label class="block text-gray-700 text-sm font-bold mb-2" for="image-upload">
                Upload a food image:
            </label>
            <div class="file-input-wrapper">
                <input type="file" id="image-upload" accept="image/*">
                <div class="upload-button">Choose File</div>
            </div>
            <img id="image-preview" src="#" alt="Image Preview" class="mx-auto mt-4 rounded-lg shadow-md border border-gray-200">
        </div>

        <button id="detect-button" class="action-button" disabled>
            Detect Food
        </button>

        <div id="loading-indicator" class="flex items-center justify-center space-x-2">
            <svg class="animate-spin h-5 w-5 text-green-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            <span>Detecting...</span>
        </div>

        <div id="results-area" class="fade-in">
            <p class="text-gray-600">Upload an image and click "Detect Food" to see the results.</p>
        </div>
    </div>

    <script>
        const imageUpload = document.getElementById('image-upload');
        const imagePreview = document.getElementById('image-preview');
        const detectButton = document.getElementById('detect-button');
        const loadingIndicator = document.getElementById('loading-indicator');
        const resultsArea = document.getElementById('results-area');

        let base64ImageData = ''; // Store the Base64 image data
        let currentMimeType = 'image/png'; // Default MIME type

        /**
         * Resizes an image to a maximum dimension while maintaining aspect ratio,
         * then converts it to a Base64 data URL.
         * @param {File} file The image file to resize.
         * @param {number} maxWidth The maximum width for the resized image.
         * @param {number} maxHeight The maximum height for the resized image.
         * @returns {Promise<string>} A promise that resolves with the Base64 data URL of the resized image.
         */
        async function resizeImage(file, maxWidth, maxHeight) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onload = function(event) {
                    const img = new Image();
                    img.onload = function() {
                        let width = img.width;
                        let height = img.height;

                        // Calculate new dimensions
                        if (width > height) {
                            if (width > maxWidth) {
                                height *= maxWidth / width;
                                width = maxWidth;
                            }
                        } else {
                            if (height > maxHeight) {
                                width *= maxHeight / height;
                                height = maxHeight;
                            }
                        }

                        // Create a canvas element
                        const canvas = document.createElement('canvas');
                        canvas.width = width;
                        canvas.height = height;
                        const ctx = canvas.getContext('2d');

                        // Draw the image onto the canvas
                        ctx.drawImage(img, 0, 0, width, height);

                        // Get the data URL from the canvas
                        // Use the original file's MIME type if possible, otherwise default to image/jpeg for better compression
                        const outputMimeType = file.type && file.type.startsWith('image/') ? file.type : 'image/jpeg';
                        const quality = 0.9; // Adjust quality for JPEG output
                        const dataUrl = canvas.toDataURL(outputMimeType, quality);
                        currentMimeType = outputMimeType; // Update the global mime type

                        resolve(dataUrl);
                    };
                    img.src = event.target.result;
                };
                reader.readAsDataURL(file);
            });
        }

        // Event listener for image file selection
        imageUpload.addEventListener('change', async function(event) {
            const file = event.target.files[0];
            if (file) {
                // Resize the image to a maximum of 1000 pixels (either width or height)
                const resizedDataUrl = await resizeImage(file, 1000, 1000);

                imagePreview.src = resizedDataUrl;
                imagePreview.style.display = 'block'; // Show the image preview

                // Get only the base64 part from the resized data URL
                base64ImageData = resizedDataUrl.split(',')[1];
                imagePreview.dataset.mimeType = currentMimeType; // Store the actual mime type used for the canvas output

                detectButton.disabled = false; // Enable the detect button
                resultsArea.innerHTML = '<p class="text-gray-600">Image loaded and resized. Click "Detect Food" to analyze.</p>';
            } else {
                imagePreview.src = '#';
                imagePreview.style.display = 'none';
                base64ImageData = '';
                imagePreview.dataset.mimeType = '';
                detectButton.disabled = true;
                resultsArea.innerHTML = '<p class="text-gray-600">Upload an image and click "Detect Food" to see the results.</p>';
            }
        });

        // Event listener for the detect button
        detectButton.addEventListener('click', async function() {
            // OpenRouter API Key
            const encodedstring = 'c2stb3ItdjEtNDJhNGFhY2YzYjkzN2I4M2ZjYzQ0OGIxZjUxMDVmOGIwOWZmNTkwNWU1ZjVkMGU5Yzg4M2E1MTE2ZGEyNTNjMw==';
            const API_TOKEN = atob(encodedstring); 

            if (!base64ImageData) {
                resultsArea.innerHTML = '<p class="text-red-500">Please upload an image first.</p>';
                return;
            }
            
            // Show loading indicator and disable button
            loadingIndicator.style.display = 'flex';
            detectButton.disabled = true;
            resultsArea.innerHTML = ''; // Clear previous results

            try {
                // OpenRouter API Endpoint for Chat Completions
                const apiUrl = "https://openrouter.ai/api/v1/chat/completions"; 
                
                // Prompt for the multimodal model (Llama 3.2 Vision)
                const prompt = "Based on the image, provide the following information:\n1. Food Name:\n2. Ingredients (short, comma-separated list):\n3. Key Nutrients (short, comma-separated list):\n4. Is this food generally healthy for elderly people? (Yes/No and a very brief reason).\n5. Is this food generally healthy for elderly people with high blood pressure, high blood sugar,high cholesterol,heart disease,kidney disease elderly? (Yes/No and a very brief reason).";
                const mimeType = imagePreview.dataset.mimeType || 'image/png'; // Use detected mime type or fallback

                const payload = {
                    "model": "meta-llama/llama-3.2-11b-vision-instruct:free", // The new vision-enabled OpenRouter model
                    "messages": [
                        { 
                            "role": "user", 
                            "content": [
                                { "type": "text", "text": prompt }, // Text part of the prompt
                                { "type": "image_url", "image_url": { "url": `data:${mimeType};base64,${base64ImageData}` } } // Image part
                            ]
                        }
                    ],
                    // You can add other parameters like temperature, max_tokens here if needed
                    // "temperature": 0.7,
                    // "max_tokens": 500
                };

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${API_TOKEN}`,
                        'HTTP-Referer': window.location.href, // Required by OpenRouter for attribution. Use your app's domain if deployed.
                        'X-Title': 'Food Detector App' // Required by OpenRouter for attribution
                    },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const responseBodyText = await response.text();
                    let errorDetails = `HTTP Error: ${response.status} ${response.statusText}`;

                    try {
                        const jsonError = JSON.parse(responseBodyText);
                        errorDetails += ` - ${JSON.stringify(jsonError)}`;
                    } catch (e) {
                        errorDetails += ` - ${responseBodyText}`;
                    }
                    throw new Error(`OpenRouter API error: ${errorDetails}`);
                }

                const result = await response.json();

                // OpenRouter (OpenAI-compatible) chat completion response structure
                if (result && result.choices && result.choices.length > 0 && result.choices[0].message && result.choices[0].message.content) {
                    const text = result.choices[0].message.content;
                    resultsArea.innerHTML = `<p class="text-gray-800 fade-in">${text.replace(/\n/g, '<br>')}</p>`;
                } else {
                    resultsArea.innerHTML = '<p class="text-red-500">No food information generated or unexpected API response structure from OpenRouter.</p>';
                }
            } catch (error) {
                console.error('Error with OpenRouter API:', error);
                resultsArea.innerHTML = `<p class="text-red-500">Error: ${error.message}. Please try again.</p>`;
            } finally {
                loadingIndicator.style.display = 'none';
                detectButton.disabled = false;
            }
        });
    </script>
</body>
</html>
